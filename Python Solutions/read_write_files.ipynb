{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "poem.txt contains famous poem \"Road not taken\" by poet Robert Frost. You have to read this file in your python program and find out words with maximum occurance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Two': 2, 'roads': 2, 'diverged': 2, 'in': 3, 'a': 3, 'yellow': 1, 'wood,\\n': 1, 'And': 6, 'sorry': 1, 'I': 8, 'could': 1, 'not': 1, 'travel': 1, 'both\\n': 1, 'be': 2, 'one': 3, 'traveler,': 1, 'long': 1, 'stood\\n': 1, 'looked': 1, 'down': 1, 'as': 5, 'far': 1, 'could\\n': 1, 'To': 1, 'where': 1, 'it': 2, 'bent': 1, 'the': 8, 'undergrowth;\\n': 1, '\\n': 3, 'Then': 1, 'took': 2, 'other,': 1, 'just': 1, 'fair,\\n': 1, 'having': 1, 'perhaps': 1, 'better': 1, 'claim,\\n': 1, 'Because': 1, 'was': 1, 'grassy': 1, 'and': 3, 'wanted': 1, 'wear;\\n': 1, 'Though': 1, 'for': 2, 'that': 3, 'passing': 1, 'there\\n': 1, 'Had': 1, 'worn': 1, 'them': 1, 'really': 1, 'about': 1, 'same,\\n': 1, 'both': 1, 'morning': 1, 'equally': 1, 'lay\\n': 1, 'In': 1, 'leaves': 1, 'no': 1, 'step': 1, 'had': 1, 'trodden': 1, 'black.\\n': 1, 'Oh,': 1, 'kept': 1, 'first': 1, 'another': 1, 'day!\\n': 1, 'Yet': 1, 'knowing': 1, 'how': 1, 'way': 1, 'leads': 1, 'on': 1, 'to': 1, 'way,\\n': 1, 'doubted': 1, 'if': 1, 'should': 1, 'ever': 1, 'come': 1, 'back.\\n': 1, 'shall': 1, 'telling': 1, 'this': 1, 'with': 1, 'sigh\\n': 1, 'Somewhere': 1, 'ages': 2, 'hence:\\n': 1, 'wood,': 1, 'Iâ€”\\n': 1, 'less': 1, 'traveled': 1, 'by,\\n': 1, 'has': 1, 'made': 1, 'all': 1, 'difference.': 1}\n",
      "Max occurances of any word is: 8\n",
      "Words with max occurances are: \n",
      "I\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "word_stats={}\n",
    "\n",
    "with open(\"poem.txt\",\"r\") as f:\n",
    "    for line in f:\n",
    "      words=line.split(' ')\n",
    "      for word in words:\n",
    "        if word in word_stats:\n",
    "          word_stats[word]+=1\n",
    "        else:\n",
    "          word_stats[word] = 1\n",
    "\n",
    "print(word_stats)\n",
    "\n",
    "word_occurances = list(word_stats.values())\n",
    "max_count = max(word_occurances)\n",
    "print(\"Max occurances of any word is:\",max_count)\n",
    "\n",
    "print(\"Words with max occurances are: \")\n",
    "for word, count in word_stats.items():\n",
    "    if count==max_count:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stocks.csv contains stock price, earnings per share and book value. You are writing a stock market application that will process this file and create a new file with financial metrics such as pe ratio and price to book ratio. These are calculated as,\n",
    "pe ratio = price / earnings per share\n",
    "price to book ratio = price / book value\n",
    "Your input format (stocks.csv) is,\n",
    "\n",
    "Company Name\tPrice\tEarnings Per Share\tBook Value\n",
    "Reliance\t1467\t66\t653\n",
    "Tata Steel\t391\t89\t572\n",
    "Output.csv should look like this,\n",
    "\n",
    "Company Name\tPE Ratio\tPB Ratio\n",
    "Reliance\t22.23\t2.25\n",
    "Tata Steel\t4.39\t0.68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstocks.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[0;32m      2\u001b[0m     out\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompany Name,PE Ratio, PB Ratio\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This will skip first line in the file which is a header\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"stocks.csv\", \"r\") as f, open(\"output.csv\", \"w\") as out:\n",
    "    out.write(\"Company Name,PE Ratio, PB Ratio\\n\")\n",
    "    next(f)  # This will skip first line in the file which is a header\n",
    "    for line in f:\n",
    "        tokens = line.split(\",\")\n",
    "        stock = tokens[0]\n",
    "        price = float(tokens[1])\n",
    "        eps = float(tokens[2])\n",
    "        book = float(tokens[3])\n",
    "        pe = round(price / eps, 2)\n",
    "        pb = round(price / book, 2)\n",
    "        out.write(f\"{stock},{pe},{pb}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
